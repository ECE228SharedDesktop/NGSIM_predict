{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ca3de5",
   "metadata": {},
   "source": [
    "# Testing neural networks on NGSIM dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a9ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharedDesktop228\\anaconda3\\envs\\ML_Env4\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x241d2f6f590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import resnet50\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "np.random.seed(228)\n",
    "random.seed(228)\n",
    "torch.manual_seed(228)\n",
    "torch.random.manual_seed(228)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db95ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharedDesktop228\\AppData\\Local\\Temp\\ipykernel_5996\\1212135371.py:2: DtypeWarning: Columns (13,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  NGSIM = pd.read_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "filename = \"Next_Generation_Simulation__NGSIM__Vehicle_Trajectories_and_Supporting_Data.csv\"\n",
    "NGSIM = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9001c3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def string2float(my_string):\n",
    "    return float(my_string.replace(',',''))\n",
    "NGSIM[\"Local_Y\"] = NGSIM[\"Local_Y\"].apply(string2float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c6507",
   "metadata": {},
   "source": [
    "# Dataset info:\n",
    "11,850,526 datapoints \n",
    "<br>\n",
    "<b>Labels:</b> \"Vehicle_ID\" \"Frame_ID\" \"Total_Frames\" \"Global_Time\" \"Local_X\" \"Local_Y\" \"Global_X\"\n",
    "                             \"Global_Y\" \"v_length\" \"v_Width\" \"v_Class\" \"v_Vel\" v_Acc Lane_ID O_Zone D_Zone Int_ID\n",
    "                             Section_ID Direction Movement Preceding Following Space_Headway Time_Headway Location\n",
    "<br>\n",
    "<b>Locations:</b> \"us-101\" \"i-80\" \"lankershim\" \"peachtree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8d30438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_list(data, location):\n",
    "    '''\n",
    "    Inputs:\n",
    "        data: NGSIM subset data according to location (pandas DataFrame)\n",
    "        location: location (string)\n",
    "    '''\n",
    "    filename = location + \"_id_list\"\n",
    "    try:\n",
    "        with open(filename, \"rb\") as fp:\n",
    "            id_list = pickle.load(fp)\n",
    "    except: \n",
    "        id_list = []\n",
    "        for i in tqdm(range(data.shape[0])):\n",
    "            if data.iloc[i].loc[\"Vehicle_ID\"] not in id_list:\n",
    "                id_list.append(data.iloc[i].loc[\"Vehicle_ID\"])\n",
    "        id_list.sort()\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            pickle.dump(id_list, fp)\n",
    "    \n",
    "    return id_list\n",
    "\n",
    "def filter_extra_IDs(vehicle_data):\n",
    "    total_frame_tracker = []\n",
    "    for i in range(vehicle_data.shape[0]):\n",
    "        if vehicle_data.iloc[i].loc[\"Total_Frames\"] not in total_frame_tracker:\n",
    "            total_frame_tracker.append(vehicle_data.iloc[i].loc[\"Total_Frames\"])\n",
    "    most_frames = max(total_frame_tracker)\n",
    "    vehicle_data = vehicle_data.loc[vehicle_data[\"Total_Frames\"] == most_frames]\n",
    "    return vehicle_data\n",
    "\n",
    "def graph_lane_vs_frame(vehicle_data):\n",
    "    Lane_ID = vehicle_data[\"Lane_ID\"].to_numpy(dtype=np.float16)   \n",
    "    fig, [ax1, ax2] = plt.subplots(2, 1, sharex=True)\n",
    "    ax1.scatter(vehicle_data[\"Frame_ID\"], Lane_ID)\n",
    "    ax2.scatter(vehicle_data[\"Frame_ID\"], vehicle_data[\"Local_X\"])\n",
    "    ax1.set_title(\"Lane ID\")\n",
    "    ax2.set_title(\"Local X\")\n",
    "    plt.xlabel(\"Frame ID\")\n",
    "\n",
    "def detect_switches(vehicle_data, delete_interval=1.5):\n",
    "    Lane_ID = vehicle_data[\"Lane_ID\"].to_numpy(dtype=int)\n",
    "    boolean_switch = np.diff(Lane_ID)\n",
    "    switch_index = np.where(boolean_switch != 0)\n",
    "    switch_index = switch_index[0] + 1\n",
    "    switch_frames = vehicle_data[\"Frame_ID\"].iloc[switch_index].to_numpy()\n",
    "    \n",
    "    # sometimes the lane switch data is fuzzy. Deleting lane switches within <delete_interval> seconds\n",
    "    if len(switch_frames) >= 2:\n",
    "        delete_frames = int(delete_interval*10)\n",
    "        frames_between_switches = np.diff(switch_frames)\n",
    "        frames_too_close = frames_between_switches < delete_frames\n",
    "        frames_too_close = np.append(False, frames_too_close)\n",
    "        switch_frames = np.delete(switch_frames, frames_too_close)\n",
    "    \n",
    "    switch_frames = validate_switches(switch_frames, vehicle_data)\n",
    "    \n",
    "    # even if no lane change, we still want to sample\n",
    "    if len(switch_frames)==0:\n",
    "        lowest_frame = vehicle_data[\"Frame_ID\"].iloc[0]+51\n",
    "        highest_frame = vehicle_data[\"Frame_ID\"].iloc[vehicle_data.shape[0]-1]-53\n",
    "        switch_frames = [random.randint(lowest_frame, highest_frame)]\n",
    "    return switch_frames\n",
    "\n",
    "def validate_switches(switch_frames, vehicle_data):\n",
    "    first_frame = vehicle_data[\"Frame_ID\"].iloc[0]\n",
    "    last_frame = vehicle_data[\"Frame_ID\"].iloc[vehicle_data.shape[0]-1]\n",
    "\n",
    "    bool_delete = np.zeros_like(switch_frames, dtype=bool)\n",
    "    \n",
    "    for index, value in enumerate(switch_frames):\n",
    "        if abs(last_frame-value) <= 53 or abs(first_frame-value) <= 53:\n",
    "            bool_delete[index] = True\n",
    "    switch_frames = np.delete(switch_frames, bool_delete)\n",
    "    return switch_frames\n",
    " \n",
    "def extract_features(switch_frame, vehicle_data, time_interval=5):\n",
    "    '''\n",
    "    Inputs:\n",
    "        switch_frame: singular lane switch frame\n",
    "        vehicle_data: same as always\n",
    "        time_interval: how much time in future and past we take into account. Default: 5s (50 frames before and after LC)\n",
    "    Returns:\n",
    "        first and second time derivatives using future values (for example: v_t calculated using x_t and x_(t+1)).\n",
    "            Each is a 100-D array, with lane switch occuring at 51st index (50th if zero-indexing). Because of \n",
    "            downsampling when taking time difference, two extra timesteps must be considered in the frame_interval\n",
    "    '''\n",
    "    delta_t = 0.1\n",
    "    num_frames = int(time_interval/delta_t*2)\n",
    "    frame_interval = np.array([switch_frame-(time_interval/delta_t), switch_frame+(time_interval/delta_t)+2], dtype=int)\n",
    "    # Extracting data within frame_interval\n",
    "    interval_data = vehicle_data.loc[vehicle_data[\"Frame_ID\"]>=frame_interval[0]]\n",
    "    interval_data = interval_data.loc[vehicle_data[\"Frame_ID\"]<=frame_interval[1]]\n",
    "    x_pos = interval_data[\"Local_X\"].to_numpy(dtype=np.float32)\n",
    "    y_pos = interval_data[\"Local_Y\"].to_numpy(dtype=np.float32)\n",
    "    assert len(x_pos)==103\n",
    "    assert len(y_pos)==103\n",
    "    \n",
    "    # Positional time derivatives\n",
    "    delta_x = np.diff(x_pos)\n",
    "    delta_y = np.diff(y_pos)\n",
    "    v_x = delta_x/delta_t\n",
    "    v_y = delta_y/delta_t\n",
    "    delta_v_x = np.diff(v_x)\n",
    "    \n",
    "#     yaw = np.arctan(np.divide(v_x,v_y))\n",
    "    yaw = np.arctan2(v_x, v_y)\n",
    "    yaw_rate = np.diff(yaw)/delta_t\n",
    "    \n",
    "    yaw = yaw[:num_frames]\n",
    "    yaw_rate = yaw_rate[:num_frames]\n",
    "    lat_vel = v_x[:num_frames]\n",
    "    lat_accel = delta_v_x/delta_t\n",
    "    lat_accel = lat_accel[:num_frames]\n",
    "    \n",
    "    extracted_data = np.zeros((num_frames, 4))\n",
    "    extracted_data[:,0] = yaw\n",
    "    extracted_data[:,1] = yaw_rate\n",
    "    extracted_data[:,2] = lat_vel\n",
    "    extracted_data[:,3] = lat_accel\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "def detect_lane_change(frame, vehicle_data):\n",
    "    '''\n",
    "    Detects and returns hot one encoding for left lane switch [1 0 0], no change [0 1 0] or right lane switch [0 0 1]\n",
    "\n",
    "    '''\n",
    "\n",
    "    prev_lane = vehicle_data.loc[vehicle_data[\"Frame_ID\"]==frame-1][\"Lane_ID\"].to_numpy(dtype=int)\n",
    "    current_lane = vehicle_data.loc[vehicle_data[\"Frame_ID\"]==frame][\"Lane_ID\"].to_numpy(dtype=int)\n",
    "    \n",
    "    if len(prev_lane)!=1 or len(current_lane)!=1:\n",
    "        return False\n",
    "\n",
    "    if current_lane == prev_lane:\n",
    "        LS = np.array([0, 1, 0])\n",
    "    elif current_lane < prev_lane:\n",
    "        LS = np.array([1, 0, 0])\n",
    "    elif current_lane > prev_lane:\n",
    "        LS = np.array([0, 0, 1])\n",
    "    return LS\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5b2b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extracted_dataset:\n",
    "    def __init__(self, num_validation_data=300,num_training_data=80,num_timesteps=100):\n",
    "        self.num_validation_data=num_validation_data\n",
    "        self.num_training_data=num_training_data\n",
    "        self.total_num_data = self.num_validation_data + self.num_training_data\n",
    "        self.num_extracted_data = 4\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        self.left_turn_data = np.zeros((self.total_num_data, self.num_timesteps, self.num_extracted_data))\n",
    "        self.right_turn_data = np.zeros((self.total_num_data, self.num_timesteps, self.num_extracted_data))\n",
    "        self.lane_keep_data = np.zeros((self.total_num_data, self.num_timesteps, self.num_extracted_data))\n",
    "        \n",
    "        self.track_num_left = 0\n",
    "        self.track_num_right = 0\n",
    "        self.track_num_keep = 0\n",
    "        \n",
    "        self.hot_dict = {\n",
    "            \"Left\": np.array([1, 0, 0]),\n",
    "            \"Keep\": np.array([0, 1, 0]),\n",
    "            \"Right\": np.array([0, 0, 1])\n",
    "        }\n",
    "        \n",
    "    def add(self, X, y):\n",
    "        if np.all(y==self.hot_dict[\"Keep\"]):\n",
    "            if self.track_num_keep < self.total_num_data:\n",
    "                self.lane_keep_data[self.track_num_keep, :, :] = X\n",
    "                self.track_num_keep += 1\n",
    "        if np.all(y==self.hot_dict[\"Left\"]):\n",
    "            if self.track_num_left < self.total_num_data:\n",
    "                self.left_turn_data[self.track_num_left, :, :] = X\n",
    "                self.track_num_left += 1\n",
    "        if np.all(y==self.hot_dict[\"Right\"]):\n",
    "            if self.track_num_right < self.total_num_data:\n",
    "                self.right_turn_data[self.track_num_right, :, :] = X\n",
    "                self.track_num_right += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03a46321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 3)\n"
     ]
    }
   ],
   "source": [
    "# LOCATIONS = [\"us-101\", \"i-80\", \"lankershim\", \"peachtree\"]\n",
    "LOCATIONS = [\"us-101\", \"i-80\"]\n",
    "my_dataset = Extracted_dataset()\n",
    "data_filename = \"labeled_data\"\n",
    "\n",
    "try:\n",
    "    with open(data_filename, \"rb\") as fp:\n",
    "        data_with_labels = pickle.load(fp)\n",
    "except:\n",
    "    for location in LOCATIONS:\n",
    "        data = NGSIM.loc[NGSIM[\"Location\"] == location]\n",
    "        id_list = get_id_list(data, location)\n",
    "\n",
    "        for i in tqdm(id_list):\n",
    "            vehicle_data = data.loc[data[\"Vehicle_ID\"] == i].sort_values(\"Frame_ID\")\n",
    "            vehicle_data = filter_extra_IDs(vehicle_data)\n",
    "\n",
    "            switch_frames = detect_switches(vehicle_data)\n",
    "\n",
    "            for single_switch_frame in switch_frames:\n",
    "                lane_change = detect_lane_change(single_switch_frame, vehicle_data)\n",
    "                if lane_change is not False:\n",
    "                    extracted_data = extract_features(single_switch_frame, vehicle_data)\n",
    "                    my_dataset.add(extracted_data, lane_change)\n",
    "                else:\n",
    "                    continue\n",
    "    left_data = np.copy(my_dataset.left_turn_data)\n",
    "    keep_data = np.copy(my_dataset.lane_keep_data)\n",
    "    right_data = np.copy(my_dataset.right_turn_data)\n",
    "\n",
    "    complete_data = np.concatenate((left_data, keep_data, right_data), axis=0)\n",
    "\n",
    "    complete_labels = np.zeros((1140,3))\n",
    "    complete_labels[0:380, :] = [1, 0, 0]\n",
    "    complete_labels[380:380*2, :] = [0, 1, 0]\n",
    "    complete_labels[380*2:, :] = [0, 0, 1]\n",
    "\n",
    "    randperm = np.random.permutation(1140)\n",
    "    shuffled_data = complete_data[randperm, :]\n",
    "    shuffled_labels = complete_labels[randperm, :]\n",
    "\n",
    "    data_with_labels = [shuffled_data, shuffled_labels]\n",
    "    data_filename = \"labeled_data\"\n",
    "    with open(data_filename, \"wb\") as fp:\n",
    "        pickle.dump(data_with_labels, fp)\n",
    "\n",
    "print(data_with_labels[0].shape)\n",
    "print(data_with_labels[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
